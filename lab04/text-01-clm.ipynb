{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thanhpolito/polito_llm/blob/main/lab04/text-01-clm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LaW7epjvmMU3"
      },
      "source": [
        "## Causal Language Modeling (CLM) - Preprocess, Training and Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEqU7bRGmMU3"
      },
      "source": [
        "In this lab, we will explore **Causal Language Modeling (CLM)**, which is a core task in training autoregressive language models like GPT-2. CLM is the process of predicting the next word in a sequence, given the previous words. This type of modeling forms the backbone of text generation tasks, where the model learns to generate coherent text by focusing only on previous tokens in the sequence.\n",
        "\n",
        "The lab is divided into three major sections:\n",
        "1. **Preprocessing**: Preparing a dataset and the labels for the CLM task and tokenizing them.\n",
        "2. **Training**: Fine-tuning a pre-trained language model like GPT-2 on a specific dataset using the CLM task.\n",
        "3. **Inference**: Evaluating the modelâ€™s performance by generating text based on input prompts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bk8lw861mMU4"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n",
        "from datasets import load_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pme25c9zmMU5"
      },
      "source": [
        "### 1. Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SB_iNqvmMU5"
      },
      "source": [
        "1. **Load the Domain-Specific Dataset**:\n",
        "   - The first step in fine-tuning GPT-2 is to load a dataset that is specific to the domain of interest. In this case, we are using a publicly available **medical dataset** from the **PubMed** collection. PubMed contains a vast number of medical articles, and fine-tuning on such a dataset can help GPT-2 generate more accurate and context-specific medical text.\n",
        "   - The dataset we're using is `\"japhba/pubmed_simple\"`, which is a simplified version of PubMed data. This dataset can be easily accessed using the `datasets` library from Hugging Face.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TAblZco6mMU5"
      },
      "outputs": [],
      "source": [
        "ds = load_dataset(\"japhba/pubmed_simple\", split=\"train\")\n",
        "train_dataset = ds.shuffle(seed=42).select(range(1000))\n",
        "eval_dataset = ds.shuffle(seed=42).select(range(1000, 1500))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFQf1lXqmMU6"
      },
      "source": [
        "We can check the contents of any one of the examples in the dataset to understand the structure of the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mea2WJapmMU6",
        "outputId": "00ffe691-f4b3-43aa-f46c-bb07c115335a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'abstract': 'Purpose The identification of abnormalities that are relatively rare within otherwise normal anatomy is a major challenge for deep learning in the semantic segmentation of medical images. The small number of samples of the minority classes in the training data makes the learning of optimal classification challenging, while the more frequently occurring samples of the majority class hamper the generalization of the classification boundary between infrequently occurring target objects and classes. In this paper, we developed a novel generative multi-adversarial network, called Ensemble-GAN, for mitigating this class imbalance problem in the semantic segmentation of abdominal images.Method The Ensemble-GAN framework is composed of a single-generator and a multi-discriminator variant for handling the class imbalance problem to provide a better generalization than existing approaches. The ensemble model aggregates the estimates of multiple models by training from different initializations and losses from various subsets of the training data. The single generator network analyzes the input image as a condition to predict a corresponding semantic segmentation image by use of feedback from the ensemble of discriminator networks. To evaluate the framework, we trained our framework on two public datasets, with different imbalance ratios and imaging modalities: the Chaos 2019 and the LiTS 2017.Result In terms of the F1 score, the accuracies of the semantic segmentation of healthy spleen, liver, and left and right kidneys were 0.93, 0.96, 0.90 and 0.94, respectively. The overall F1 scores for simultaneous segmentation of the lesions and liver were 0.83 and 0.94, respectively.Conclusion The proposed Ensemble-GAN framework demonstrated outstanding performance in the semantic segmentation of medical images in comparison with other approaches on popular abdominal imaging benchmarks. The Ensemble-GAN has the potential to segment abdominal images more accurately than human experts.',\n",
              " 'country': 'US'}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "train_dataset[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "La4o8KGRmMU7"
      },
      "source": [
        "We see that the each entry is a dictionary with two keys:\n",
        "- \"abstract\": The abstract of the medical article\n",
        "- \"country\": The country where the article was published (we will not use this information in this lab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZcMrShomMU7"
      },
      "source": [
        "2. **Tokenize the Dataset**:\n",
        "   - The next step is to **tokenize** the data so that it can be processed by GPT-2.\n",
        "   - GPT-2 does not natively use a padding token, since it does not require fixed length inputs. For this reason, we will substite it with the EOS token as suggested by transformers library (remember, we are also passing an attention mask, so whatever value is used for padding will be ignored by the model!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l6p8v9njmMU7"
      },
      "outputs": [],
      "source": [
        "# TODO: Tokenize the Dataset using the GPT-2 tokenizer\n",
        "# Hint: Use the `map` method of the dataset object\n",
        "model_name = \"gpt2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "tokenizer.pad_token = tokenizer.eos_token  # Set padding token to EOS token\n",
        "\n",
        "def tokenize_function(samples):\n",
        "    # Tokenize the text column `abstract` in the dataset (set `truncation=True` and `padding=\"max_length\"`)\n",
        "    # NOTE: You can either use tokenzier as a global variable, or\n",
        "    # use a closure to capture the tokenizer variable\n",
        "    return tokenizer(samples[\"abstract\"], truncation=True, padding=\"max_length\")\n",
        "\n",
        "# Apply the tokenization function to the dataset\n",
        "\n",
        "# NOTE: you should map the dataset using the tokenize function.\n",
        "# (You can optionally consider using the argument `batched=True` for better performance,\n",
        "# as long as tokenize_function can handle the batch! [note2: the tokenizer can do that!])\n",
        "tokenized_dataset = train_dataset.map(tokenize_function,batched=True)\n",
        "tokenized_dataset_eval = eval_dataset.map(tokenize_function,batched=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTAM9sfCmMU7"
      },
      "source": [
        "3. **Add labels to the Dataset for Next Token Prediction**:\n",
        "   - In this step, we will add the **labels** that will be used during the next token prediction task.\n",
        "   - In autoregressive language modeling, the **labels** represent the same sequence as the input, shifted one token to the right. This is because the model is trained to predict the next token in the sequence given the previous tokens.\n",
        "   - The shifting of the tokens is already handled automatically by the `Trainer` class. We just pass an extra attribute named `labels` to the dataset (when this argument is passed to the model, it will know to compute the loss for us!)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7525f67"
      },
      "source": [
        "# TODO: Add labels to the dataset\n",
        "def add_labels(samples):\n",
        "    # NOTE: The labels, in causal modeling, should be the same as the input_ids\n",
        "    samples[\"labels\"] = samples[\"input_ids\"]\n",
        "    return samples\n",
        "\n",
        "tokenized_dataset = tokenized_dataset.map(add_labels, batched=True)\n",
        "tokenized_dataset_eval = tokenized_dataset_eval.map(add_labels, batched=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset[0]"
      ],
      "metadata": {
        "id": "PaxV-4K-oqYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOyDvEzxmMU8"
      },
      "source": [
        "### 2. Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jaHiwXfmMU8"
      },
      "source": [
        "1. **Fine-Tune the GPT-2 Model**:\n",
        "   - Set up the model and finetune it using the medical dataset.\n",
        "   - The pipeline to be followed is the same that we have already seen in the previous lab (`lab03 - 01-bert`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 943,
          "referenced_widgets": [
            "c9bcfa8c50874fe88fd63b28291955db",
            "8e79f0a9fd5645aebe8304e13f7cb5d2",
            "776a718fab814fb88d0865ef80e2865b",
            "36ec6da08bcf459aad1205bab95f40ff",
            "6b7bcf42e1f14c028676741821867ac7",
            "1994479599544941ba6a0cf2e0926ad8",
            "1643c1da33d64cd294ea8ba5ac364538",
            "6efebdc92d604e3bb1cdf1faa2eb11b7",
            "090234d9280f43c49388f9e907d65386",
            "846edc1ee16243429b0de61eeaa20adf",
            "b2e87c9fafb44636a1c51971a124e41f",
            "4ffeb413b7a14c58a5f8f0066de5d1a6",
            "d5bbea26a2874906a629cf55e08bb72a",
            "568171c94a5d4c608055883c854693f7",
            "d22ca00c290645e0811a23c32723b02d",
            "bb27f818093e4b5fba7ee816a348fef9",
            "98dfce9a6c3446a68a5d479d83c3a0c6",
            "e533d477bcfc4144861a2cfa25ec76b7",
            "24c06aeea5b04ad589b1256415a8dd15",
            "7a39cd0beb614d8dac7ccf5189668e8a",
            "15989bd835a74085a746b1bed4056da4",
            "28cbe684479a494ebf6ada4831045377"
          ]
        },
        "id": "d428be71",
        "outputId": "b89e8c5a-7275-4388-c895-ab24a56d7326"
      },
      "source": [
        "# Set Training Parameters\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./gpt2-medical-finetuned\",\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=6,\n",
        "    save_total_limit=2,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=100,\n",
        "    eval_steps=10,\n",
        "    eval_strategy=\"steps\",\n",
        ")\n",
        "\n",
        "# TODO: Initialize GPT-2 Model\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "# TODO: Fine-Tune the Model with the `Trainer` method and pass also the eval_dataset\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset,\n",
        "    eval_dataset=tokenized_dataset_eval,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "# Save the Fine-Tuned Model\n",
        "model.save_pretrained(\"./gpt2-medical-finetuned\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c9bcfa8c50874fe88fd63b28291955db"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4ffeb413b7a14c58a5f8f0066de5d1a6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mthanhnv-it23\u001b[0m (\u001b[33mstefano-gamba-social-politecnico-di-torino\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.22.2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251027_074507-vw55442i</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/stefano-gamba-social-politecnico-di-torino/huggingface/runs/vw55442i' target=\"_blank\">fine-bird-1</a></strong> to <a href='https://wandb.ai/stefano-gamba-social-politecnico-di-torino/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/stefano-gamba-social-politecnico-di-torino/huggingface' target=\"_blank\">https://wandb.ai/stefano-gamba-social-politecnico-di-torino/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/stefano-gamba-social-politecnico-di-torino/huggingface/runs/vw55442i' target=\"_blank\">https://wandb.ai/stefano-gamba-social-politecnico-di-torino/huggingface/runs/vw55442i</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='167' max='167' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [167/167 18:44, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.737956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.727048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.725884</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.722512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.722605</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.721063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.721319</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.719583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.718908</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.909700</td>\n",
              "      <td>0.718428</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>0.909700</td>\n",
              "      <td>0.717794</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.909700</td>\n",
              "      <td>0.717495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>0.909700</td>\n",
              "      <td>0.716894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>0.909700</td>\n",
              "      <td>0.716372</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.909700</td>\n",
              "      <td>0.716092</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>0.909700</td>\n",
              "      <td>0.715819</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICjQmhEPmMU8"
      },
      "source": [
        "### 3. Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVTWhcLcmMU8"
      },
      "source": [
        "1. **Compare Text Generation Before and After Fine-Tuning**:\n",
        "   - Generate text using both the original pre-trained GPT-2 model and the fine-tuned model.\n",
        "   - Provide the same input prompt and observe the differences in the outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "21-1PteBmMU8"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "# TODO: Load the pre-trained and fine-tuned GPT-2 models\n",
        "pretrained_model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
        "finetuned_model = AutoModelForCausalLM.from_pretrained(\"./gpt2-medical-finetuned\")\n",
        "\n",
        "#\n",
        "\n",
        "# TODO: Tokenize the prompt\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "prompt = \"The patient presents with chest pain and shortness of breath.\"\n",
        "\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "input_ids = inputs['input_ids']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R79o6YZBrNu7",
        "outputId": "c156de3f-f9e3-4223-c68a-217c5e507a01"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[  464,  5827, 10969,   351,  7721,  2356,   290,  1790,  1108,   286,\n",
              "          8033,    13]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZuNGPdVmMU8",
        "outputId": "bdd54060-41b5-4586-ccd3-86798aa927b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Before Fine-Tuning (Pre-Trained GPT-2)**:\n",
            "The patient presents with chest pain and shortness of breath. The patient is in a state of shock and is unable to breathe. The patient is in a state of shock and is unable to breathe. The patient is in a state of shock and is unable to breathe. The patient is in a state of shock and is unable to breathe. The patient is in a state of shock and is unable to breathe. The patient is in a state of shock and is unable to breathe. The patient is in\n"
          ]
        }
      ],
      "source": [
        "# TODO: Generate Output of the Model Before Fine-Tuning (use `generate` and then `decode` methods of the model and tokenizer)\n",
        "output_pretrained = pretrained_model.generate(input_ids, max_length=100, num_return_sequences=1, pad_token_id=tokenizer.eos_token_id,temperature=1.0)\n",
        "generated_pretrained = tokenizer.decode(output_pretrained[0], skip_special_tokens=True)\n",
        "\n",
        "print(\"**Before Fine-Tuning (Pre-Trained GPT-2)**:\")\n",
        "print(generated_pretrained)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUpGEqHKmMU9",
        "outputId": "671d3ca1-3d9a-4fa2-861e-a69b8fd0da64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**After Fine-Tuning (Fine-Tuned on Medical Dataset)**:\n",
            "The patient presents with chest pain and shortness of breath. The patient is in a state of shock and is unable to breathe. The patient is unable to breathe. The patient is unable to breathe. The patient is unable to breathe. The patient is unable to breathe. The patient is unable to breathe. The patient is unable to breathe. The patient is unable to breathe. The patient is unable to breathe. The patient is unable to breathe. The patient is unable to breathe. The patient is unable\n"
          ]
        }
      ],
      "source": [
        "# TODO: Generate Output of the Model After Fine-Tuning\n",
        "output_finetuned = finetuned_model.generate(input_ids, max_length=100, num_return_sequences=1, pad_token_id=tokenizer.eos_token_id,temperature=1.0)\n",
        "generated_finetuned = tokenizer.decode(output_finetuned[0], skip_special_tokens=True)\n",
        "\n",
        "print(\"**After Fine-Tuning (Fine-Tuned on Medical Dataset)**:\")\n",
        "print(generated_finetuned)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QgTrBPYmMU9"
      },
      "source": [
        "<span style=\"color:red\">Extra stuff!</span>\n",
        "\n",
        "Training the model in this way produces batches with potentially very different lengths. This can be inefficient, as the model will have to pad the sequences to the length of the longest sequence in the batch.\n",
        "\n",
        "To avoid this, we can use a technique called **Dynamic Padding**. This technique groups the sequences in the batch by length and pads them to the length of the longest sequence in each group. This way, the model only has to pad the sequences to the length of the longest sequence in each group, which can significantly reduce the amount of padding required.\n",
        "\n",
        "As a first exercise, quantify the number of pad tokens being used in various situations:\n",
        "1. You pad all batches to the maximum allowed sequence length (1024 for GPT-2, this is what we used so far)\n",
        "2. You pad the entire batch to the length of the longest sequence in the batch (generate the batches by randomly sampling sentences)\n",
        "3. You pad the entire batch to the length of the longest sequence in the batch (generate the batches by placing sentences of similar lengths together)\n",
        "\n",
        "Next, introduce dynamic padding and compare the execution times of the previous execution and the one with dynamic padding.\n",
        "\n",
        "You can use the following resources to help you with this exercise:\n",
        "- `group_by_length` parameter ([TrainingArguments](https://huggingface.co/docs/transformers/v4.46.0/en/main_classes/trainer#transformers.TrainingArguments.group_by_length)) (parameter to group together samples with similar lengths)\n",
        "- `DataCollatorForSeq2Seq` ([DataCollatorForSeq2Seq](https://huggingface.co/docs/transformers/main_classes/data_collator#transformers.DataCollatorForSeq2Seq)) (collator function that aggregates samples into batches and pads them to the maximum length of the batch)\n",
        "\n",
        "Note: you may find that the validation losses you observe may be different from the previous ones. This is because the cross entropy loss is computed as an average across tokens, and the number of tokens in a batch can vary depending on the padding strategy used."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c9bcfa8c50874fe88fd63b28291955db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8e79f0a9fd5645aebe8304e13f7cb5d2",
              "IPY_MODEL_776a718fab814fb88d0865ef80e2865b",
              "IPY_MODEL_36ec6da08bcf459aad1205bab95f40ff"
            ],
            "layout": "IPY_MODEL_6b7bcf42e1f14c028676741821867ac7"
          }
        },
        "8e79f0a9fd5645aebe8304e13f7cb5d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1994479599544941ba6a0cf2e0926ad8",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_1643c1da33d64cd294ea8ba5ac364538",
            "value": "model.safetensors:â€‡100%"
          }
        },
        "776a718fab814fb88d0865ef80e2865b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6efebdc92d604e3bb1cdf1faa2eb11b7",
            "max": 548105171,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_090234d9280f43c49388f9e907d65386",
            "value": 548105171
          }
        },
        "36ec6da08bcf459aad1205bab95f40ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_846edc1ee16243429b0de61eeaa20adf",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b2e87c9fafb44636a1c51971a124e41f",
            "value": "â€‡548M/548Mâ€‡[00:18&lt;00:00,â€‡33.9MB/s]"
          }
        },
        "6b7bcf42e1f14c028676741821867ac7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1994479599544941ba6a0cf2e0926ad8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1643c1da33d64cd294ea8ba5ac364538": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6efebdc92d604e3bb1cdf1faa2eb11b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "090234d9280f43c49388f9e907d65386": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "846edc1ee16243429b0de61eeaa20adf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2e87c9fafb44636a1c51971a124e41f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ffeb413b7a14c58a5f8f0066de5d1a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d5bbea26a2874906a629cf55e08bb72a",
              "IPY_MODEL_568171c94a5d4c608055883c854693f7",
              "IPY_MODEL_d22ca00c290645e0811a23c32723b02d"
            ],
            "layout": "IPY_MODEL_bb27f818093e4b5fba7ee816a348fef9"
          }
        },
        "d5bbea26a2874906a629cf55e08bb72a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98dfce9a6c3446a68a5d479d83c3a0c6",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_e533d477bcfc4144861a2cfa25ec76b7",
            "value": "generation_config.json:â€‡100%"
          }
        },
        "568171c94a5d4c608055883c854693f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24c06aeea5b04ad589b1256415a8dd15",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7a39cd0beb614d8dac7ccf5189668e8a",
            "value": 124
          }
        },
        "d22ca00c290645e0811a23c32723b02d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15989bd835a74085a746b1bed4056da4",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_28cbe684479a494ebf6ada4831045377",
            "value": "â€‡124/124â€‡[00:00&lt;00:00,â€‡4.99kB/s]"
          }
        },
        "bb27f818093e4b5fba7ee816a348fef9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98dfce9a6c3446a68a5d479d83c3a0c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e533d477bcfc4144861a2cfa25ec76b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "24c06aeea5b04ad589b1256415a8dd15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a39cd0beb614d8dac7ccf5189668e8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "15989bd835a74085a746b1bed4056da4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28cbe684479a494ebf6ada4831045377": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}